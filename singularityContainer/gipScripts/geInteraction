#############################################################################
# giptools                                                                  #
#                                                                           #
# Authors: Giovanni Bussotti                                                #
# Copyright (c) 2021  Institut Pasteur                                      #
#                                                                           #
#                                                                           #
# This program is free software: you can redistribute it and/or modify      #
# it under the terms of the GNU General Public License as                   #
# published by the Free Software Foundation, either version 3 of the        #
# License, or (at your option) any later version.                           #
#                                                                           #
# This program is distributed in the hope that it will be useful,           #
# but WITHOUT ANY WARRANTY; without even the implied warranty of            #
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             #
# GNU General Public License for more details.                              #
#                                                                           #
# You should have received a copy of the GNU General Public License         #
# along with this program.  If not, see <https://www.gnu.org/licenses/>.    #
#                                                                           #
#############################################################################

suppressPackageStartupMessages(library("argparse"))
parser <- ArgumentParser(description="Detect CNV genes across multiple samples and produce correlation-based networks")
parser$add_argument("--samplesList" , nargs="+", required=TRUE, help="File with a column named \"sample\" listing samples names. Additional TSV columns will be used to annotate the output figures. \"field\"_COLOR columns are used to map colors to the additional fields [required]" )
parser$add_argument("--gipOut"  , help="GIP output directory [default %(default)s]" , default="gipOut")
parser$add_argument("--outName" , help="Output name [default %(default)s]" , default="gipOut/sampleComparison/geInteraction")
parser$add_argument("--chrs"    , nargs="+" , help="Chromosomes to use. If \"NA\" it uses the same chromsomes as GIP [default %(default)s]" , default="NA")
parser$add_argument("--minMAPQ" , type="integer" , help="Remove genes with MAPQ < --minMAPQ [default %(default)s]", default=0 )
parser$add_argument("--minDelta" , type="integer" , help="Min normalized coverage delta between samples [default %(default)s]" , default=1)
parser$add_argument("--minMaxCov" , type="character" , nargs="+" , help="Use only genes with normalized coverage >Value1 or <Value2 in at least one sample. If \"NA\" no filter is applied [default %(default)s]" , default="NA" )
parser$add_argument("--rmNotSigGenes" , action="store_true" , help="Use only genes with significant coverage in at least one of the samples " , default=FALSE)
parser$add_argument("--heatmapType" , help="Gene normalized coverage value transformation used for the CNVs vs samples heatmap [scaled|log10|saturated|flatten] [default %(default)s]" , default="scaled" )
parser$add_argument("--covSaturation" , type="double" , help="Gene normalized coverage saturation value. DEPENDENCY --heatmapType \"saturated\" or \"flatten\"  [default %(default)s]" , default=3)
parser$add_argument("--quantileSaturation" , type="double" , nargs="+" , help="Provide two numbers. Saturate the colors of the gene CNVs vs samples heatmap for quantiles < num1 or > num2. DEPENDENCY --heatmapType [scaled|log10] [default %(default)s]" , default=c(0.05,0.95))
parser$add_argument("--doNotClusterSamples"  , action="store_false" , help="Do not cluster heatmap columns. Show the samples in the same order as in --samplesList [default %(default)s]" , default=TRUE)
parser$add_argument("--clusteringMethod" , help="Heatmaps clustering method [ward.D2|ward|single|complete|average|mcquitty|median|centroid] [default %(default)s]" , default="complete")
parser$add_argument("--cutree_cnv" , type="integer" , help="Based on the hierarchical clustering, divide the genes in this number of clusters [default %(default)s]" , default=1)
parser$add_argument("--cutree_samp" , type="integer" , help="Based on the hierarchical clustering, divide the samples in this number of clusters  [default %(default)s]" , default=1)
parser$add_argument("--show_geneNames"  , action="store_true" , help="Show gene names in the heatmaps [default %(default)s]" , default=FALSE)
parser$add_argument("--show_sampNames"  , action="store_true" , help="Show sample names in the heatmaps [default %(default)s]" , default=FALSE)
parser$add_argument("--cnvPlotDim" , nargs="+", type="double", help="CNVs vs samples heatmap file height and width values [default %(default)s]" , default=c(11,6) )
parser$add_argument("--corPlotDim" , nargs="+", type="double", help="CNVs vs CNVs heatmap file height and width values [default %(default)s]" , default=c(11,11) )
parser$add_argument("--lolPlotDim" , nargs="+", type="double", help="Lollipop plot file height and width values [default %(default)s]" , default=c(7,4) )
parser$add_argument("--kmeansClusters" , help="NETWORK. Use this number of k-means clusters for network clustering. If \"NA\" use mclust [default %(default)s]" , default="NA")
parser$add_argument("--MCLinflation" , help="NETWORK. Use this inflation MCL value for network clustering. Higher inflation values result in increased cluster granularity. If \"NA\" use mclust [default %(default)s]" , default="NA")
parser$add_argument("--MCLexpansion" , type="integer" , help="NETWORK. MCL expansion value. DEPENDENCY --MCLinflation not \"NA\" [default %(default)s]" , default=2)
parser$add_argument("--clMaxSDdist" , type="character", help="NETWORK. Gene CNVs with distance from the cluster centroid > --clMaxSDdist standard deviations from the mean distance are removed from the cluster. High values make this filter unffective. [default %(default)s]" , default="Inf")
parser$add_argument("--clMinSize"   , type="integer" , help="NETWORK. Min number of members in a cluster [default %(default)s]" , default=2)
parser$add_argument("--edgesMeanCorFilter" , action="store_true" , help="NETWORK. Remove edges representing CNV correlation scores lower than the mean absolute CNV correlation" , default=FALSE)
parser$add_argument("--edgesPvalueFilter"  , type="double" , help="NETWORK. Remove edges with adjusted pvalue below this threshold  [default %(default)s]" , default="0.01")
parser$add_argument("--debug"  , action="store_true" , help="Dump session and quit" , default=FALSE)

args <- parser$parse_args()
#patch NA
for (n in names(args)){
  if(args[[n]][1] == "NA"){args[[n]] <- NA}  
}
for (n in names(args)){assign(n,args[[n]]) }

suppressPackageStartupMessages(library("gplots"))
suppressPackageStartupMessages(library("FactoMineR"))
suppressPackageStartupMessages(library("RColorBrewer"))
suppressPackageStartupMessages(library("data.table"))
suppressPackageStartupMessages(library("openxlsx"))
suppressPackageStartupMessages(library("fastcluster"))
suppressPackageStartupMessages(library("ggplot2"))
suppressPackageStartupMessages(library("entropy"))
suppressPackageStartupMessages(library("reshape2"))
suppressPackageStartupMessages(library("randomcoloR"))
suppressPackageStartupMessages(library("pheatmap"))

if(debug){library(session);save.session("session_DEBUG_geInteraction");quit()}

#setup
if(! dir.exists(gipOut)){
  stop("ERROR. gipOut directory does not exists")
  quit(save = "no", status = 1, runLast = FALSE)
}
outDir <- paste0(gipOut,"/sampleComparison/")
system(paste0("mkdir -p ", outDir))
sampInfo <- read.table(samplesList,stringsAsFactors=F,header=T,sep="\t",comment.char = "")
samples  <- sampInfo$sample
chrSel      <- as.character(read.table(paste0(gipOut,"/samples/",samples[1],"/chrCoverageMedians_",samples[1]),header=T)[,1])
chrSize     <- read.table(paste0(gipOut,"/genome/genome.chrSize"),sep="\t", stringsAsFactors = F, header=F , col.names=c("chr","size"))
chrSize$chr <- as.character(chrSize$chr)
chrSize     <- chrSize[match(chrSel,chrSize$chr),]
if (is.na (chrs[1])){
  chrs <- chrSize$chr
}
chrSize <- chrSize[chrSize$chr %in% chrs,]
geFunDf <- read.delim(paste0(gipOut,"/genome/geneFunction.tsv") , sep="\t", stringsAsFactors = F, header=F ,col.names=c("geId","geneFunction"))

##############################
#read input and measure delta#
##############################
row.names(sampInfo) <- samples
allFiles <- list()

for (i in 1:length(samples)){
  N <- samples[i]
  allFiles[[N]] <- fread(cmd=paste0("gunzip -c ", gipOut , "/samples/" , N , "/" , N , ".covPerGe.gz") , colClasses=list(character=1), data.table=FALSE)
  #filter just if it is not a deletion (we keep deletions)
  allFiles[[N]] <- allFiles[[N]][ allFiles[[N]]$normalizedMeanCoverage <= 0.01 | (allFiles[[N]]$normalizedMeanCoverage > 0.01 & allFiles[[N]]$MAPQ >= minMAPQ) ,]  
  allFiles[[N]]$chr    <- gsub(x=allFiles[[N]]$locus,pattern="(.+):(.+)-(.+)$",replacement="\\1")
  allFiles[[N]]$start  <- as.numeric(gsub(x=allFiles[[N]]$locus,pattern="(.+):(.+)-(.+)$",replacement="\\2"))
  allFiles[[N]]$end    <- as.numeric(gsub(x=allFiles[[N]]$locus,pattern="(.+):(.+)-(.+)$",replacement="\\3"))
  allFiles[[N]]        <- allFiles[[N]][,c("chr" , "start" , "end" , "normalizedMeanCoverage","gene_id")]
  names(allFiles[[N]]) <- c(paste0("chr_",N) , paste0("start_",N) , paste0("end_",N) , paste0("score_",N) , "tag"  )  
}
df = Reduce(function(...) merge(..., by="tag" ,all=T , sort=F), allFiles) #a bin can be present in a sample but filtered in another. These will we in df as NA scores
row.names(df) <- df$tag
df <- df[,c(names(allFiles[[1]][1:3]) ,  names(df)[grepl(x=names(df),pattern="score_")])]
names(df)[1:3] <- c("chr","start","end")

#generate correlating genes for testing purpose only
#if (DEVELOP_ONLY) {
# df$score_m1 <- runif(nrow(df))
# df$score_m3 <- runif(nrow(df)) * 1.5
# df$score_m6 <- runif(nrow(df)) * 2  
# df$score_m8 <- runif(nrow(df)) * 4
#makeCorrelatingGenes <- function(n,mu1,mu2,r,row1 , row2) {
# library(MASS)
# data = mvrnorm(n=n, mu=c(mu1, mu2), Sigma=matrix(c(1, r, r, 1), nrow=2), empirical=TRUE)
# data[data < 0]=0.1
# df[c(row1,row2),scoreCols] = t(data)
#}
#scoreCols <- names(df)[grepl(x=names(df),pattern="score_")]
#makeCorrelatingGenes(n=length(scoreCols) , mu1=3 , mu2=3 , r=0.95 , row1=1, row2=2)
#makeCorrelatingGenes(n=length(scoreCols) , mu1=3 , mu2=3 , r=0.99 , row1=2, row2=3)
#makeCorrelatingGenes(n=length(scoreCols) , mu1=3 , mu2=3 , r=0.9 , row1=3, row2=4)
#makeCorrelatingGenes(n=length(scoreCols) , mu1=3 , mu2=3 , r=0.99 , row1=4, row2=5)
#makeCorrelatingGenes(n=length(scoreCols) , mu1=3 , mu2=3 , r=0.99 , row1=5, row2=10)
#makeCorrelatingGenes(n=length(scoreCols) , mu1=3 , mu2=3 , r=-0.95 , row1=10, row2=100)
#makeCorrelatingGenes(n=length(scoreCols) , mu1=3 , mu2=3 , r=-0.99 , row1=1, row2=101)
#makeCorrelatingGenes(n=length(scoreCols) , mu1=3 , mu2=3 , r=-0.9 , row1=2, row2=102)
#makeCorrelatingGenes(n=length(scoreCols) , mu1=3 , mu2=3 , r=-0.99 , row1=30, row2=50)
#makeCorrelatingGenes(n=length(scoreCols) , mu1=3 , mu2=3 , r=-0.99 , row1=140, row2=142)
#}

########
#filter#
########
#remove the bins filtered in some samples but present in others
df <- df[complete.cases(df),]
names(df) <- gsub(x=names(df),pattern="score_(.*)",replacement="\\1")
#remove genes that are never significant
if (rmNotSigGenes) {
  allSigGe <- NULL
  for (i in 1:length(samples)){
   allSigGe <- c(allSigGe , row.names(read.table(paste0(gipOut , "/samples/" , N , "/" , N , ".covPerGe.significant.tsv"))))
  }
  allSigGe <- unique(allSigGe)
  df <- df[row.names(df) %in% allSigGe,]
  if (nrow(df) < 2) {print("< 2 genes left removing non significant genes. Quitting..") ; quit()}
}
#delta filter
df$delta <- apply( subset(df,select=-c(1,2,3)) , 1 , function(x){d=max(x)-min(x)} )
df <- df[df$delta >= minDelta,]
if (nrow(df) < 2) {print("< 2 genes show a delta coverage greather than --minDelta. Quitting..") ; quit()}
#min max cov filter
if (! is.na (minMaxCov[1])) {
  minMaxCov <- as.numeric(minMaxCov)
  dMax <- apply( subset(df,select=-c(1,2,3)) , 1 , max )
  dMin <- apply( subset(df,select=-c(1,2,3)) , 1 , min )
  df <- df[dMax > minMaxCov[1] | dMin < minMaxCov[2],]
  if (nrow(df) < 2) {print("< 2 genes show a coverage > or < --minMaxCov Quitting..") ; quit()}
}
#chr filter
df <- df[df$chr %in% chrs,]
df <- df[with(df, order(chr, start)), ]
if (nrow(df) < 2) {print("< 2 genes left after filtering. Quitting..") ; quit()}


###############################
#map CNVs to chromosome colors#
###############################
#if n<3 brew.pal gives error. we provide colors manually
palette0 <- NULL
if (length(unique(df$chr)) == 1) {
  palette0 <- "#a6cee3"
} else if (length(unique(df$chr)) == 2) {
  palette0 <- c("#a6cee3","#1f78b4")
} else {
  palette0 <- colorRampPalette(brewer.pal(12,"Paired"))(n = length(unique(df$chr)))
}
chrCol <- data.frame( chrs=unique(df$chr) , colors=palette0 ,stringsAsFactors=F)
cnvChrColors <- as.matrix(chrCol[match(df$chr,chrCol$chrs),"colors"])
colnames(cnvChrColors)<-"chr"
row.names(cnvChrColors) <- row.names(df)

######################
#SUMMARY INFO SAMPLES#
######################
#SAMPLES
samplInfoColList <- list()
sampFeats <- names(sampInfo)[-1][! grepl("_COLOR" , names(sampInfo)[-1])]
if (length(sampFeats) > 0) {
  for (feat in sampFeats){
    featCol = paste0(feat,"_COLOR")
    if (featCol %in% names(sampInfo)) {
      samplInfoColList[[feat]] <- unique(data.frame( feature=sampInfo[,feat] ,  colors=sampInfo[,featCol], stringsAsFactors=F))
      #sanity
      if (any(table(samplInfoColList[[feat]]$feature) != 1 ) || any(table(samplInfoColList[[feat]]$colors) != 1 )){
        stop(paste("ERROR. In",feat," identical elements must have the same color. Different elements must have different colors"))
        quit(save = "no", status = 1, runLast = FALSE) 
      }
    } else {
      print(paste("Color column not specified for the",feat,"feature. Using random colors"))
      set.seed(123)
      samplInfoColList[[feat]] <- data.frame( feature=unique(sampInfo[,feat]) ,  colors=distinctColorPalette(length(unique(sampInfo[,feat]))), stringsAsFactors=F)
      sampInfo[[featCol]] <- samplInfoColList[[feat]] [ match(sampInfo[[feat]] , samplInfoColList[[feat]]$feature) , "colors" ]
    }
  }
}



###################
#SUMMARY INFO CNVS#
###################
cnvInfo <- data.frame(gene_id=row.names(df) , chromosome=df$chr , chrColor=cnvChrColors[row.names(df),"chr"] ,stringsAsFactors=F)
row.names(cnvInfo) <- row.names(df)

#add CNV correlation to cnvInfo
melting <- function (df,value.name){
  melted <- reshape2::melt(as.matrix(df),varnames=c("cnv1","cnv2"),value.name=value.name)
  melted$cnv1<- as.character(melted$cnv1)
  melted$cnv2<- as.character(melted$cnv2)
  row.names(melted) <- paste0(melted$cnv1 ,"_",melted$cnv2)
  return(melted)
}
mr  <- as.matrix(subset(df , select=-c(chr,start,end,delta) ))
cmr <- round(cor(t(mr)),digits=2)
cmrMelt <- melting(cmr,"correlation")

#%%%psych corr.test function (vectorial and very fast)%%%
fisherz <- function (rho) {
    0.5 * log((1 + rho)/(1 - rho))
}
corr.test <- function (x, y = NULL, use = "pairwise", method = "pearson", adjust = "holm", alpha = 0.05, ci = TRUE) {
    cl <- match.call()
    if (is.null(y)) {
        r <- cor(x, use = use, method = method)
        sym <- TRUE
        n <- t(!is.na(x)) %*% (!is.na(x))
    }
    else {
        r <- cor(x, y, use = use, method = method)
        sym = FALSE
        n <- t(!is.na(x)) %*% (!is.na(y))
    }
    if ((use == "complete") | (min(n) == max(n))) 
        n <- min(n)
    t <- (r * sqrt(n - 2))/sqrt(1 - r^2)
    p <- 2 * (1 - pt(abs(t), (n - 2)))
    se <- sqrt((1 - r * r)/(n - 2))
    nvar <- ncol(r)
    p[p > 1] <- 1
    if (adjust != "none") {
        if (is.null(y)) {
            lp <- upper.tri(p)
            pa <- p[lp]
            pa <- p.adjust(pa, adjust)
            p[upper.tri(p, diag = FALSE)] <- pa
        }
        else {
            p[] <- p.adjust(p, adjust)
        }
    }
    z <- fisherz(r[lower.tri(r)])
    if (ci) {
        if (min(n) < 4) {
            warning("Number of subjects must be greater than 3 to find confidence intervals.")
        }
        alpha <- 1 - alpha/2
        dif <- qnorm(alpha)
        if (sym) {
            if (is.matrix(n)) {
                se <- 1/sqrt(n[lower.tri(n)] - 3)
            }
            else {
                se <- 1/sqrt(n - 3)
            }
            lower <- fisherz2r(z - dif * se)
            upper <- fisherz2r(z + dif * se)
            ci <- data.frame(lower = lower, r = r[lower.tri(r)], 
                upper = upper, p = p[lower.tri(p)])
            cnR <- abbreviate(colnames(r), minlength = 5)
            k <- 1
            for (i in 1:(nvar - 1)) {
                for (j in (i + 1):nvar) {
                  rownames(ci)[k] <- paste(cnR[i], cnR[j], sep = "-")
                  k <- k + 1
                }
            }
        }
        else {
            z <- fisherz(r)
            se <- 1/sqrt(n - 3)
            lower <- as.vector(fisherz2r(z - dif * se))
            upper <- as.vector(fisherz2r(z + dif * se))
            ci <- data.frame(lower = lower, r = as.vector(r), 
                upper = upper, p = as.vector(p))
            cnR <- abbreviate(rownames(r), minlength = 5)
            cnC <- abbreviate(colnames(r), minlength = 5)
            k <- 1
            for (i in 1:ncol(y)) {
                for (j in 1:ncol(x)) {
                  rownames(ci)[k] <- paste(cnR[j], cnC[i], sep = "-")
                  k <- k + 1
                }
            }
        }
    }
    else {
        ci <- NULL
    }
    result <- list(r = r, n = n, t = t, p = p, se = se, adjust = adjust, 
        sym = sym, ci = ci, Call = cl)
    class(result) <- c("psych", "corr.test")
    return(result)
}
#%%%END%%%
#corr pvalue
cmr_pVal <- as.data.frame(corr.test(t(mr),ci=FALSE,adjust="none")$p)
#cmr_pVal is a symmetrical matrix describing each against each p values of correlation coefficients
#the number of tests is n(n-1)/2, as we do not test the correlation of each variable with itself
#Therefore we adjust p.value considering just half the matrix, and copy the results on the other half
ltri <- lower.tri(cmr_pVal)
utri <- upper.tri(cmr_pVal)
cmr_pVal[ltri] <- p.adjust(cmr_pVal[ltri], method = "BH")
cmr_pVal[utri] <- t(cmr_pVal)[utri]
cmr_pValMelt <- melting(cmr_pVal,"pvalue")

#most corr genes
diag(cmr) <- 0
cnvInfo$mostNegCorrCNVname  <- apply(cmr,1,function(x){mostNegCorr <- names(sort(x)[1])    })
cnvInfo$mostNegCorrCNVvalue <- apply(cmr,1,function(x){mostNegCorr <- sort(x)[1]    })
cnvInfo$mostNegCorrCNVadjPval <- cmr_pValMelt[paste0(row.names(cnvInfo),"_",cnvInfo$mostNegCorrCNVname),"pvalue"]
cnvInfo$mostNegCorrCNVgeneId <-cnvInfo[match(cnvInfo$mostNegCorrCNVname,row.names(cnvInfo)),"gene_id"]
cnvInfo$mostPosCorrCNVname <- apply(cmr,1,function(x){mostPosCorr <- names(tail(sort(x),n=1))    })
cnvInfo$mostPosCorrCNVvalue <- apply(cmr,1,function(x){mostPosCorr <- tail(sort(x),n=1)    })
cnvInfo$mostPosCorrCNVadjPval <- cmr_pValMelt[paste0(row.names(cnvInfo),"_",cnvInfo$mostPosCorrCNVname),"pvalue"]
cnvInfo$mostPosCorrCNVgeneId <-cnvInfo[match(cnvInfo$mostPosCorrCNVname,row.names(cnvInfo)),"gene_id"]
cnvInfo$medianCorrCNV <- apply(cmr,1,function(x){round(median(x),3)    })
diag(cmr)  <- 1

#add CNV SD to cnvInfo#
cnvInfo$SD <- apply(mr,1,sd)

#prepare pheatmap ribons
sampInfoColObj <- NULL
if (length(sampFeats) > 0) {
  sampInfoColObj <- sampInfo [ , sampFeats , drop=FALSE]
}
cnvInfoRowObj <- cnvInfo[,c("chromosome"),drop=FALSE]
pheAnnCols <- list()
pheAnnCols$chromosome <- chrCol$colors
names(pheAnnCols$chromosome) <- chrCol$chrs
for (feat in sampFeats){
  pheAnnCols[[feat]] <- samplInfoColList[[feat]]$colors
  names(pheAnnCols[[feat]]) <- samplInfoColList[[feat]]$feature
}

zlim = function (mx,quantLims){
  quants <- quantile(mx,probs=c(quantLims))
  mx[mx < quants[1]] =  quants[1]
  mx[mx > quants[2]] =  quants[2]
  return(mx)
}
palette <- c()
pheInMr <- NULL
if (heatmapType == "scaled"){
  palette <-  colorRampPalette(c("red","green"))(n = 299)
  pheInMr <- zlim(t(scale(t(mr),center=T,scale=T)),quantileSaturation)
} else if (heatmapType == "log10"){
  palette <-  colorRampPalette(c("red","green"))(n = 299)
  pheInMr <- zlim(log10(mr+0.1),quantileSaturation)
} else if (heatmapType == "flatten"){
  palette <- colorRampPalette(c("black", "white","blue","red"))(n = 299)
  pheInMr  <- mr - apply(mr,1,min)
  pheInMr[pheInMr > covSaturation] = covSaturation
} else if (heatmapType == "saturated"){
  palette <- colorRampPalette(c("black", "white","blue","red"))(n = 299)
  pheInMr <-  mr
  pheInMr[pheInMr > covSaturation] = covSaturation
} else {
  stop("ERROR. heatmapType not recognized")
  quit(save = "no", status = 1, runLast = FALSE) 
}
#there is no easy way to show xlab and ylab, so I give the info in the title
#there is no way to give a title to the legend
#1)CNV vs SAMPLE
pdf(paste0(outName,".CNV.pdf"), height=cnvPlotDim[1] , width=cnvPlotDim[2])
pheRes  <- pheatmap(pheInMr[,samples],  color=palette , scale="none" , show_rownames=show_geneNames , 
           show_colnames=show_sampNames , clustering_method=clusteringMethod ,annotation_row=cnvInfoRowObj , 
           annotation_col=sampInfoColObj , annotation_colors=pheAnnCols , cutree_rows = cutree_cnv , cutree_cols = cutree_samp , 
           cluster_cols=doNotClusterSamples , height=11 , width=7 , 
           main=paste("geCNV (row) VS sample (col),",heatmapType,"coverage"))
invisible(dev.off())
palette3 <- colorRampPalette(brewer.pal(name="PiYG",n=8))(100)

#2) CNV VS CNV correlation 
pdf(paste0(outName,".corr.pdf"), height=corPlotDim[1] , width=corPlotDim[2])
pheResCor  <- pheatmap(cmr,  color=palette3 , scale="none" , show_rownames=show_geneNames , show_colnames=show_geneNames ,
             clustering_method=clusteringMethod ,annotation_row=cnvInfoRowObj , annotation_col=cnvInfoRowObj , 
             annotation_colors=pheAnnCols , cutree_rows = cutree_cnv , cutree_cols = cutree_cnv , 
             main="geCNV (row) VS geCNV (col), coverage correlation")
invisible(dev.off())

#3) LOLLIPOP (sorted like the CNV correlation heatmap)
pdf(paste0(outName,".lolli.pdf"), height=lolPlotDim[1] , width=lolPlotDim[2])
lollipopIdSelection <- rev(rownames(cmr[pheResCor$tree_row[["order"]],]))
lollipopData <- cnvInfo[lollipopIdSelection,c("mostNegCorrCNVvalue","mostNegCorrCNVadjPval","mostPosCorrCNVvalue","mostPosCorrCNVadjPval","medianCorrCNV","SD")]
lollipopData$id <- row.names(cnvInfo[lollipopIdSelection,])
lollipopData$id <- factor(lollipopData$id,levels=row.names(cnvInfo[lollipopIdSelection,]))
p <- ggplot(lollipopData) 
p <- p + geom_segment( aes(x=id, xend=id, y=mostNegCorrCNVvalue, yend=mostPosCorrCNVvalue), color="grey") 
p <- p + geom_point( aes(x=id, y=medianCorrCNV),size=0.1,color="black" ) 
p <- p + geom_point( aes(x=id, y=mostNegCorrCNVvalue, size=mostNegCorrCNVadjPval,color=mostNegCorrCNVvalue ) ) 
p <- p + geom_point( aes(x=id, y=mostPosCorrCNVvalue,size=mostPosCorrCNVadjPval ,color=mostPosCorrCNVvalue) ) 
p <- p + coord_flip() + xlab("Gene CNV") +ylab("Correlation") + ylim(-1,1) + theme_light() + labs(size="Adjusted P-value",color="Correlation") 
p <- p + scale_color_gradient2(low=palette3[1], high=palette3[100] , mid=palette3[50] ) #+ scale_size_continuous(breaks = c(0 , 0.00001 , 0.01 , 0.5 , 1)) #+ theme(plot.margin = unit(c(1,15,1,1), "cm")) 
if(! show_geneNames ) {
  p <- p + theme(axis.text.y=element_blank()) 
}
print(p)
invisible(dev.off())

#4) PCA
theme_gip <- function(){     
    theme_bw() %+replace%    
    theme(axis.text.x  = element_text(angle = 90), 
      axis.text.y  = element_text(size = 14) , 
      axis.title   = element_text(size=14,face="bold"),
      legend.title = element_text(face = "bold", size = 14),
      legend.text  = element_text(size = 12))
}
pdf(paste0(outName,".overview.pdf"))
resPca <- PCA(t(mr),graph=FALSE)
plot(resPca)
#colour by sampInfo
if(length(sampFeats) > 0){
  pcaCoord <- as.data.frame(resPca$ind$coord)
  for (n in colnames(sampInfoColObj)) {
    pcaCoord$feature <- sampInfo[rownames(pcaCoord),n]
    p <- ggplot(pcaCoord , aes(x=Dim.1 , y=Dim.2 , color=feature)) + geom_point( size=1.5 ) + ggtitle(paste("Sample PCA colored by",n))
    p <- p + scale_color_manual(name=n , values=sampInfo[[paste0(n,"_COLOR")]] , breaks=sampInfo[[n]])
    p <- p + theme_gip() + theme(legend.position="bottom" , axis.text  = element_text(size = 14)) 
    if( length(unique(pcaCoord$feature)) > 12 ){
      p <- p + theme(legend.text  = element_text(size = 8)) 
    }
    p <- p + xlab("Principal component dimension 1") + ylab("Principal component dimension 2")
    print(p)
  }
}

#5) ENTROPY/SD of CNVs
par(mfrow=c(1,2))
hist(apply(mr,1,sd),breaks=100,col="blue",xlab="CNV standard deviation",main="")
cnvEntropy <- apply(mr,1,function(x){
 m <- mean(x)
 bins <- c(0 , m/2, m, m+1 , m+2 , m+3 , Inf) 
 counts <- table(cut(x,breaks=bins))
 entropy(counts, unit="log2") 
})
cnvInfo$entropy <- cnvEntropy[ match(cnvInfo$gene_id , names(cnvEntropy)) ]
hist(cnvEntropy,breaks=100,col="red",xlab="CNV entropy (bits)",main="")
invisible(dev.off())

#out table
branchGoupSamp      <- cutree(pheRes$tree_col, k=cutree_samp)
sampInfo$branchGroupHeatmapCNV <- branchGoupSamp[ match(sampInfo$sample,names(branchGoupSamp)) ]
branchGoupCnv       <- cutree(pheRes$tree_row, k=cutree_cnv)
cnvInfo$branchGroupHeatmapCNV <- branchGoupCnv[ match(cnvInfo$gene_id,names(branchGoupCnv)) ]
branchGoupCnvCor    <- cutree(pheResCor$tree_row, k=cutree_cnv)
cnvInfo$branchGroupHeatmapCorr <- branchGoupCnvCor[ match(cnvInfo$gene_id,names(branchGoupCnvCor)) ]
#sort as in heatmap1
cnvInfo  <- cnvInfo[ rownames(mr)[pheRes$tree_row[["order"]]] , ]
sampInfo <- sampInfo[ colnames(mr)[pheRes$tree_col[["order"]]] , ]
df <- df[ rownames(mr)[pheRes$tree_row[["order"]]]  ,  c("chr","start","end",colnames(mr)[pheRes$tree_col[["order"]]],"delta") ]
df$geneFunction <-  geFunDf[ match(row.names(df) , geFunDf$geId ) , "geneFunction"]
##sort as in heatmap2
#cmr <- cmr[ rownames(cmr)[pheResCor$tree_row[["order"]]]  , colnames(cmr)[pheResCor$tree_col[["order"]]] ]

df <- cbind(row.names(df) , df)
names(df)[1] <- "gene_id"
write.xlsx(file=paste0(outName,".CNV.xlsx") , x=list(sampleInfo=sampInfo , cnvInfo=cnvInfo , normGeneCoverage=df  ) , asTable=TRUE) #, cnvCorrelations=as.data.frame(cmr))
#save memory
rm(df , cnvInfo)


###############################
###############################
####PART 2: NETWORK ANALYSIS###
###############################
###############################
#setup
if (! is.na(MCLinflation) && ! is.na(kmeansClusters)){
  stop("ERROR. you must chose either kmeans or MCL for network clustering")
  quit(save = "no", status = 1, runLast = FALSE)  
}
if (! is.na(MCLinflation)) {
  MCLinflation <- as.integer(MCLinflation)
} 
if (! is.na(kmeansClusters)) {
  kmeansClusters <- as.integer(kmeansClusters)
} 
if(clMaxSDdist == "Inf") {
  clMaxSDdist <- Inf
} 
clMaxSDdist <- as.numeric(clMaxSDdist)

suppressPackageStartupMessages(library("mclust"))
suppressPackageStartupMessages(library("reshape2"))
suppressPackageStartupMessages(library("igraph"))
suppressPackageStartupMessages(library("MCL"))

filterDistantCNVs <- function(mat,classification) {
  tdf <- as.data.frame(mat)
  tdf$cl   <- classification[match(names(classification) , row.names(tdf)    )]
  splitDf <- split(tdf,tdf$cl)
  #remove clusters of just 1 element
  for (cl in names(splitDf)){ if(length(splitDf[[cl]][,1]) == 1){splitDf[cl] <- NULL}}
  clCentroids <- lapply( splitDf , function(x){ 
    v <- as.vector(apply(x[,row.names(x)] , 2  , mean)) ; 
    names(v) <- row.names(x) ; return(v)    })
  for (cl in names(clCentroids)){
    centroid <- clCentroids[[cl]]
    cluster  <- tdf[names(centroid),names(centroid)]
    memberDistFromCentroid <- apply(cluster,1,function(x){dist(rbind(x , centroid)) }  )
    meanMemberDistFromCentroid <- mean(memberDistFromCentroid)
    sdMemberDistFromCentroid <- sd(memberDistFromCentroid)
    outliers <- names(memberDistFromCentroid[ abs(memberDistFromCentroid - meanMemberDistFromCentroid)/sdMemberDistFromCentroid > clMaxSDdist])
    splitDf[[cl]] <- splitDf[[cl]][ ! row.names(splitDf[[cl]]) %in% outliers , ]
    #remove small clusters
    if(length(splitDf[[cl]][,1]) < clMinSize){splitDf[cl] <- NULL}
  }
  #regenerate/rename clusters
  i=0; 
  dfCl <- NULL
  corClList <- list()
  for(n in names(splitDf)){
     i=i+1; 
     splitDf[[n]]$cl <- factor(i)
     CorrCluster <- as.data.frame(cmr[row.names(splitDf[[n]]),row.names(splitDf[[n]])])
     CorrClusterGeFun <- geFunDf[ match(row.names(splitDf[[n]]) , geFunDf$geId ) , "geneFunction"]
     CorrClusterGeFun[is.na(CorrClusterGeFun)] <- "NA"
     corClList[[paste0("CorrCluster",n)]] <- cbind(data.frame(gene_id=row.names(splitDf[[n]]) , geneFunction=CorrClusterGeFun ,  CorrCluster))
     dfCl <- rbind(dfCl,splitDf[[n]])
  }
  corClList[["filteredCNVs"]] <- data.frame(gene_id=row.names(tdf) [! row.names(tdf) %in% row.names(dfCl)])
  corClList[["dfCl"]] <- dfCl
  return(corClList)
}

#1) cluster of absolute CNV correlations
absCmr       <- abs(cmr)
classification <- NULL
if (is.na(kmeansClusters) && is.na(MCLinflation)) {
  set.seed(123)
  mc_absCmr      <- Mclust(absCmr)
  classification <- mc_absCmr$classification
} else if (! is.na(kmeansClusters)) {
  set.seed(123)
  classification <- kmeans(as.matrix(absCmr),centers=kmeansClusters)$cluster
} else {
  set.seed(123)
  classification <- mcl(absCmr,addLoops=F,inflation=MCLinflation,expansion=MCLexpansion)$Cluster
  names(classification) <- row.names(absCmr)
}
 
corClList <- filterDistantCNVs(absCmr,classification)
absCmrFilter <- corClList[["dfCl"]]
corClList[["dfCl"]] <- NULL
cnvCl <- as.character(absCmrFilter$cl)
names(cnvCl)<- row.names(absCmrFilter)
#square df
absCmrFilter <- absCmrFilter[,row.names(absCmrFilter)]

#Prepare edges and vertices
edges <- reshape2::melt(as.matrix(absCmrFilter), varnames=c("n1","n2"),value.name="weight")
#remove duplicated edges (better doing that manually as you do. the package fuction "simplify" alters the weights)
edges <- edges[ ! edges$n1 == edges$n2 , ]
edges$tag <- apply(edges,1,function(x){  s<- sort(c(x[["n1"]] , x[["n2"]])); paste(s, collapse = '_')  })
edges <- edges[! duplicated(edges$tag),c("n1","n2","weight")]
edges$corr <- "positive"
selector <- cmrMelt[paste0(edges$n1 , "_" , edges$n2) , "correlation"] < 0
edges$corr[selector] <- "negative"
edges$pvalue<- cmr_pValMelt[paste0(edges$n1 , "_" , edges$n2),"pvalue"]
vertices <- data.frame(n=row.names(absCmrFilter)  , cl=cnvCl[row.names(absCmrFilter)],stringsAsFactors=F)
row.names(vertices) <- vertices$n

#maps
clColMap   <- data.frame(cl=unique(cnvCl),col=colorRampPalette(brewer.pal(8, "Dark2"))(length(unique(cnvCl))),stringsAsFactors=F)
corrColMap <- data.frame(corrType=c("positive","negative") ,col=c( "tomato", "blue"),stringsAsFactors=F)

#NET
net <- graph_from_data_frame(edges, directed=FALSE, vertices=vertices)
#delete weak edges
if (edgesMeanCorFilter) {
  cut.off <- mean(edges$weight) 
  net <- delete_edges(net, E(net)[weight<cut.off])
} 
net <- delete_edges(net, E(net)[pvalue>=edgesPvalueFilter])
#map vertices to clusters
V(net)$color <- clColMap [ match( vertices[V(net),"cl"] , clColMap$cl ) , "col" ]
# Compute node degrees (#links) and use that to set node size (saturating at 3 to avoid enormous nodes)
deg <- degree(net, mode="all")
deg[deg > 3]=3
V(net)$size <- deg
# Setting them to NA will render no labels:
V(net)$label <- NA
#remove arrow
E(net)$arrow.size <- 0 
# Set edge width based on weight:
E(net)$width <- E(net)$weight/2
#E(net)$width <- 1+E(net)$weight/12
#map edge color to pos/neg corr
edge.color <- corrColMap[ match(E(net)$corr,corrColMap$corrType) , "col"]
set.seed(123)
l <- layout_with_fr(net)
pdf(paste0(outName,".network.pdf"))
plot(net, layout=l , edge.color=edge.color, edge.curved=.1)
legend(x=-1.5, y=-1, legend=clColMap$cl , pch=21, col=clColMap$col , pt.bg=clColMap$col, pt.cex=1, cex=.7, bty="n", ncol=2 ,title="Cluster")
legend(x=-1.2  , y=-1, legend=corrColMap$corrType , pch=NA,  lty = c(1, 1) , col=corrColMap$col , pt.cex=1, cex=.7, bty="n", ncol=1 ,title="Correlation")
invisible(dev.off())
#write net edges tsv
printEdgesDf <- as.data.frame(cbind( get.edgelist(net) , E(net)$weight , E(net)$corr , E(net)$pvalue ))
names(printEdgesDf) <- c("gene1","gene2","absolute_correlation","direction","adjusted_pvalue")
#write.table(printEdgesDf,quote=F,sep="\t",append=F,row.names=F,col.names=T,file=paste0(outName,"_filteredCNVcls/network_edges.tsv") )
corClList[["networkEdges"]] <- printEdgesDf
write.xlsx(file=paste0(outName,".network.xlsx") , x=corClList , asTable=TRUE )

######################
#useful for debugging#
#netDf = as_data_frame(net, what="edges")
#netDf[netDf$to == "LdBPK_260017300",]
##highlight vertex function
#highlightVertex <- function (net,vertex){
#  vertexSel <- V(net)[name==vertex]
#  vcol <- rep("grey40", vcount(net))
#  vcol[vertexSel] <- "#ff9d00"
#  plot(net, vertex.color=vcol)
#}
##highlight vertex function version 2 (creates a test.pdf file and highlights in pink, keeps the same layout, can highlight multiple vertices in one go)
#highlightVertex2 <- function (net,vertex){
#  vertexPosition <- which(row.names(as_data_frame(net,what="vertices")) %in% vertex)
#  #V(net)$label[vertexPosition] <- vertex
#  V(net)$color[vertexPosition] <- "pink"
#  pdf("test.pdf")
#  plot(net, layout=l , edge.color=edge.color) #, edge.curved=.1)
#  dev.off()
#}
##highlight vertex LdBPK_260017000 neighbours
#neigh.nodes = neighbors(net, V(net)[name=="LdBPK_260017000"], mode="all")
#vcol <- rep("grey40", vcount(net))
#vcol[neigh.nodes] <- "#ff9d00"
#plot(net, vertex.color=vcol)


###############################
###############################
####PART 3: NETWORK D3#########
###############################
###############################
suppressPackageStartupMessages(library("networkD3"))

#net.d3 <- igraph_to_networkD3(net,group=V(net)$cl) works but I am not 100% sure since the net nodes are not sorted as people say online. better convert net to d3 manually like in here

#extract all edges pairs (from "V1" to "V2")
edgesNet <- as.data.frame(as_edgelist(net, names = TRUE),stringsAsFactors=F)
edgesNet <- edgesNet[with(edgesNet, order(V1)), ]
#each node must be associated a unique integer identifier (starting with 0)
allEdgesNames <- c(edgesNet$V1,edgesNet$V2)
nodeAsIntegers <- as.integer(factor(allEdgesNames))-1
names(nodeAsIntegers) <- allEdgesNames
nodeAsIntegers <- sort(nodeAsIntegers[!duplicated(nodeAsIntegers)])
edgesNet.d3    <- data.frame(source=nodeAsIntegers[edgesNet$V1], target=nodeAsIntegers[edgesNet$V2] , weight=apply(edgesNet,1,function(x){absCmr[x[1],x[2]]}))
#sorting the nodes dataframe in the same order as defined by the node IDs integers
verticesNet.d3    <- vertices[names(nodeAsIntegers),]
verticesNet.d3$n <- factor(verticesNet.d3$n)

#edge colors
corr.d3       <- rep("positive",length(edgesNet[,1]))
selector.d3   <- apply(edgesNet,1,function(x){cmr[x[["V1"]] , x[["V2"]] ] < 0  } )
corr.d3[selector.d3] <- "negative"
edge.color.d3     <- corrColMap[ match(corr.d3 , corrColMap$corrType) , "col"]
#nodes color
verticesColourScale <- paste0("d3.scaleOrdinal() .domain([\""  ,   paste(clColMap$cl,collapse="\",\"")  ,   "\"]) . range([\"",   paste(clColMap$col,collapse="\",\"")      ,"\"])"  )
verticesNet.d3$size <- deg[match(verticesNet.d3$n,names(deg))]
#action when clicking node
MyClickScript <- 'alert("You clicked " + d.name + " which is in row " +  (d.index + 1) +  " of your original R data frame");'

fn <- forceNetwork(Links = edgesNet.d3, Nodes = verticesNet.d3, Source="source", Target="target" , NodeID = "n", Group = "cl",linkWidth = .5 , fontSize=12, zoom=F, legend=T, opacity = 0.8, charge=-10, width = 1000, height = 1000 , Value="weight" , linkColour = edge.color.d3 , colourScale=verticesColourScale , Nodesize="size" , radiusCalculation=JS("d.nodesize + 2") , clickAction = MyClickScript)
saveNetwork(fn, paste0(normalizePath(outDir) , "/geInteraction.network.d3.html") , selfcontained = TRUE)
 

